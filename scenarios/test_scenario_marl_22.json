{
    "environment": 
    {
	    "num_channels": 10,
	    "max_steps": 100,
        "comments": [
            "\"Scenario 4\" from the MARL paper.",

            "Two agents, and two fixed-hop frequency entities.",
            "The observation modes vary, and the reward modes are both 'dsa' (target entities are irrelevant)."
        ],
        "agents": {
            "agent_1": {
                "observation_mode": "detect",
                "reward_mode": "dsa",
                "target_entity": null
            },
            "agent_2": {
                "observation_mode": "classify",
                "reward_mode": "dsa",
                "target_entity": null
            }
        }
    },
    "entities": 
    {
        "fixed_hop_freq_1":
        {
            "type": "FixedHopFreq",
            "channels": [1,2,3,4,5,6,7,8],
            "onoff": [1,1,0],
            "rand_hop": 0,
            "modem_params":
            {
                "type": "n_fmcw",
                "center_frequency": [0.0,0.0],
                "bandwidth": 1.0,
                "start": 0.0,
                "duration": 1.0
            }
        },
        "fixed_hop_freq_2":
        {
            "type": "FixedHopFreq",
            "channels": [3,6,8,1,4,2,5,7],
            "onoff": [1,1,0],
            "rand_hop": 0,
            "modem_params":
            {
                "type": "ask",
                "order": 4,
                "filter": "RRC",
                "center_frequency": [0.0,0.0],
                "bandwidth": 0.5,
                "start": 0.0,
                "duration": 1.0
            }
        }
    },
    "render":
    {
        "render_mode": "pyqt",
        "render_fps": 100,
        "render_history": 20,
        "render_background": "black",
        "observation_mode": "classify"
    }
}